# SignalTree Performance Benchmarks

This document describes the enhanced variance benchmark scripts and their CLI options.

## Scripts

- `micro-benchmarks-variance.mjs` (Angular engine build)
- `micro-benchmarks-variance-vanilla.mjs` (Vanilla engine)

Both now share unified formatting utilities and support the same CLI flags.

## Directory Layout (Organized)

```
scripts/performance/
  micro-benchmarks-variance*.mjs
  paths.mjs
  migrate-legacy-results.mjs
performance/
  results/          # ephemeral (gitignored)
    micro/
      angular/latest.json
      vanilla/latest.json
  baselines/        # versioned, commit these
    micro/
      angular/baseline.json
      vanilla/baseline.json
  (legacy flat JSON files have been migrated and removed)
```

```
scripts/performance/                # scripts only (no longâ€‘lived JSON outputs)
performance/                        # organized artifact tree
  baselines/
    micro/<engine>/baseline.json    # committed variance baselines
    macro/baseline.json (optional)
    size/baseline.json              # size baseline
  results/ (gitignored)             # ephemeral latest outputs
    micro/<engine>/latest.json
    macro/latest.json
    macro/median.json
    size/latest.json
  history/
    macro/benchmark-median-*.json   # archived median summaries
```

Legacy JSON files that used to sit beside scripts have been removed or migrated; only transient `latest*.json` now appear under `performance/results/`.

## CLI Flags

| Flag                     | Alias  | Description                                                                            | Default                                                          |
| ------------------------ | ------ | -------------------------------------------------------------------------------------- | ---------------------------------------------------------------- | --------- |
| `--iterations <n>`       | `-i`   | Outer sample loop count (per metric)                                                   | Angular: create 60 / others 120; Vanilla: create 50 / others 100 |
| `--inner <n>`            |        | Inner loop iterations per timing sample                                                | Metric-specific defaults (10/20/40/50)                           |
| `--baseline <file>`      |        | Path to prior JSON output to compare medians                                           | none                                                             |
| `--fail-on-regression`   |        | Exit with code 1 if any regression detected (median slower than threshold pct)         | off                                                              |
| `--regression-pct <n>`   |        | Regression threshold as fractional (0.10 = +10% slower). Applies to median comparison. | 0.10                                                             |
| `--json` / `--json-only` |        | Suppress tables and write structured JSON summary                                      | off                                                              |
| `--json-file <file>`     |        | Output path for structured JSON (when `--json`)                                        | `<latest>.json` with `-full` suffix                              |
| `--thresholds <json      | file>` |                                                                                        | Override threshold constants (inline JSON or path)               | built-ins |
| `--no-color`             |        | Disable ANSI coloring                                                                  | env `NO_COLOR` respected                                         |
| `--no-emoji`             |        | Remove emojis from headings / tips                                                     | off                                                              |

## Output Files

Primary quick stats (always written):

- Angular: `performance/results/micro/angular/latest.json` (legacy discovery fallback: organized under `scripts/performance/` then flat `latest-micro-bench-stats.json`)
- Vanilla: `performance/results/micro/vanilla/latest.json` (legacy discovery fallback: organized under `scripts/performance/` then flat `latest-micro-bench-stats-vanilla.json`)

If `--json` is specified, an extended JSON is written (default `<primary>-full.json` or as provided via `--json-file`).

## JSON Schema (Extended)

```jsonc
{
  "ts": "ISO timestamp",
  "engine": "vanilla" | undefined,
  "results": [
    {
      "label": "metric name",
      "mean": Number,
      "median": Number,
      "stddev": Number,
      "p95": Number,
      "samples": [Number, ...] // first few sorted samples
    }
  ],
  "thresholds": {
    "median": { "good": Number, "medium": Number },
    "stddevRatio": { "good": Number, "medium": Number },
    "tailRatio": { "good": Number, "medium": Number }
  },
  "regressionPct": Number,
  "regressions": [
    {
      "label": String,
      "baselineMedian": Number,
      "newMedian": Number,
      "deltaMedian": Number,
      "pct": Number,          // fractional (0.12 = +12%)
      "baselineStddevRatio": Number,
      "newStddevRatio": Number,
      "deltaStddevRatio": Number,
      "baselineTailRatio": Number,
      "newTailRatio": Number,
      "deltaTailRatio": Number,
      "regression": true      // always true for entries in this list
    }
  ]
}
```

## Threshold Overrides

Pass either a JSON string or path to a file via `--thresholds`:

Inline example:

```bash
node scripts/performance/micro-benchmarks-variance.mjs --thresholds '{"median":{"good":0.0008,"medium":0.004}}'
```

File example (`custom-thresholds.json`):

```json
{
  "median": { "good": 0.0008, "medium": 0.004 },
  "stddevRatio": { "good": 0.2, "medium": 0.4 }
}
```

Then:

```bash
node scripts/performance/micro-benchmarks-variance-vanilla.mjs --thresholds custom-thresholds.json
```

Only supplied keys are merged (shallow assign per category).

## Baseline Comparison Logic

For each metric present in both current and baseline JSONs:

- Compute `deltaMedian = current.median - baseline.median`
- Percentage `pct = deltaMedian / baseline.median` (0 if baseline median is 0)
- A regression is flagged if `pct > regressionPct` (default 0.10 = >10% slower median).

If `--fail-on-regression` is given and any regression is detected, process exits with code 1 (suitable for CI gating).

## Planned Enhancements (Future Work)

- Stddev and tail ratio deltas added to JSON output.
- Potential future flag to gate on variance/tail changes.
- Include stddev and tail ratio deltas in JSON export.
- Optional CSV export.
- Micro benchmark scripts parity (flags + variance style optionally enabled).
- Aggregated multi-run stability mode (run N sessions, aggregate).
- CI GitHub Action for automated baseline management.

## Migrating Legacy Files

A helper script migrates legacy flat JSON files into the organized directory layout and (optionally) removes the originals once CI & tooling are updated.

Run a dry run first (recommended):

```bash
node scripts/performance/migrate-legacy-results.mjs --dry-run --verbose
```

Then perform the migration (writes organized copies, keeps legacy):

```bash
node scripts/performance/migrate-legacy-results.mjs
```

Force overwrite existing organized files (e.g. placeholder baselines) and remove legacy originals:

```bash
node scripts/performance/migrate-legacy-results.mjs --force --remove-legacy
```

Flags:

| Flag              | Description                                           |
| ----------------- | ----------------------------------------------------- |
| `--dry-run`       | Show planned copies without writing                   |
| `--force`         | Overwrite organized targets even if they exist        |
| `--remove-legacy` | Delete legacy flat JSON sources after successful copy |
| `--quiet`         | Suppress normal log output                            |
| `--verbose`       | Extra per-file detail (skips, removals)               |

The script normalizes the `engine` field: ensures it's present for vanilla, omitted for angular. Placeholder baselines (empty `results` or `_note` marker) are replaced when a legacy baseline exists unless `--dry-run`.

## Quick Examples

Run Angular variance with JSON output and custom thresholds:

```bash
node scripts/performance/micro-benchmarks-variance.mjs --iterations 80 --inner 25 --json --json-file tmp/angular-full.json --thresholds custom-thresholds.json
```

Compare against baseline and fail if regressions (auto baseline discovery if not provided):

```bash
node scripts/performance/micro-benchmarks-variance-vanilla.mjs \
  --baseline scripts/performance/baselines/micro/vanilla/baseline.json \
  --fail-on-regression
```

Disable color & emoji (CI friendly):

```bash
node scripts/performance/micro-benchmarks-variance.mjs --no-color --no-emoji --json
```
